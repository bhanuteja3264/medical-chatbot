const { processTextWithAI, processImageWithAI, processAudioWithAI, processDocumentWithAI } = require('./utils/aiService');

async function testGroqCapabilities() {
  console.log('ğŸ§ª Testing Groq AI Complete Integration\n');
  console.log('='.repeat(80));
  
  // Test 1: Text Processing
  console.log('\nğŸ“ TEST 1: Text Processing (Llama 3.3 70B)');
  console.log('-'.repeat(80));
  try {
    const textResult = await processTextWithAI('I have a mild headache and feeling tired. What should I do?');
    console.log('âœ… Text Response:', textResult.content.substring(0, 200) + '...');
    console.log('âœ… Explanation:', textResult.explanation.substring(0, 150) + '...');
    console.log('âœ… Provider:', textResult.provider);
  } catch (error) {
    console.error('âŒ Text test failed:', error.message);
  }
  
  console.log('\n' + '='.repeat(80));
  console.log('\nâœ… All Groq Integration Tests Completed!');
  console.log('\nAvailable Capabilities:');
  console.log('  ğŸ“ Text: Llama 3.3 70B Versatile');
  console.log('  ğŸ“· Images: Llama 4 Scout 17B (vision model)');
  console.log('  ğŸ¤ Audio/Speech: Whisper Large V3 Turbo');
  console.log('  ğŸ¥ Video: Llama 4 Scout + Whisper');
  console.log('  ğŸ“„ Documents: PDF/Word/Text extraction + Llama 3.3 70B');
  console.log('  ğŸ” Explanations: SHAP-inspired reasoning for all responses');
}

testGroqCapabilities().catch(console.error);
